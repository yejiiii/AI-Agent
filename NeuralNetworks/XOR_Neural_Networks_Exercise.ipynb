{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. SOLVIGN A XOR PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR PROBLEM\n",
    "![XOR](./XOR_problem.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN example for XOR Problem\n",
    "![NN_Example](./NN_example.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.03129391]\n",
      " [0.0266546 ]\n",
      " [0.02415052]\n",
      " [0.01920663]]\n",
      "Loss: \n",
      "0.4752579190156717\n",
      "\n",
      "\n",
      "# 1000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.00102879]\n",
      " [0.99890895]\n",
      " [0.9989661 ]\n",
      " [0.00112499]]\n",
      "Loss: \n",
      "1.1458387667774322e-06\n",
      "\n",
      "\n",
      "# 2000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[7.19863579e-04]\n",
      " [9.99239519e-01]\n",
      " [9.99273817e-01]\n",
      " [7.83964545e-04]]\n",
      "Loss: \n",
      "5.596194638218385e-07\n",
      "\n",
      "\n",
      "# 3000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[5.84182003e-04]\n",
      " [9.99384003e-01]\n",
      " [9.99409331e-01]\n",
      " [6.35029753e-04]]\n",
      "Loss: \n",
      "3.682182159085657e-07\n",
      "\n",
      "\n",
      "# 4000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[5.03733933e-04]\n",
      " [9.99469439e-01]\n",
      " [9.99489822e-01]\n",
      " [5.46995380e-04]]\n",
      "Loss: \n",
      "2.736822776771461e-07\n",
      "\n",
      "\n",
      "# 5000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[4.49050503e-04]\n",
      " [9.99527406e-01]\n",
      " [9.99544606e-01]\n",
      " [4.87276999e-04]]\n",
      "Loss: \n",
      "2.174533738120966e-07\n",
      "\n",
      "\n",
      "# 6000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[4.08811629e-04]\n",
      " [9.99570004e-01]\n",
      " [9.99584963e-01]\n",
      " [4.43397937e-04]]\n",
      "Loss: \n",
      "1.802201552139754e-07\n",
      "\n",
      "\n",
      "# 7000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[3.77619576e-04]\n",
      " [9.99602990e-01]\n",
      " [9.99616276e-01]\n",
      " [4.09422538e-04]]\n",
      "Loss: \n",
      "1.537712072536103e-07\n",
      "\n",
      "\n",
      "# 8000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[3.52532518e-04]\n",
      " [9.99629497e-01]\n",
      " [9.99641479e-01]\n",
      " [3.82121463e-04]]\n",
      "Loss: \n",
      "1.34026392530733e-07\n",
      "\n",
      "\n",
      "# 9000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[3.31793098e-04]\n",
      " [9.99651395e-01]\n",
      " [9.99662330e-01]\n",
      " [3.59568313e-04]]\n",
      "Loss: \n",
      "1.1873069264521442e-07\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Train is Done...\n",
      "####################\n",
      "\n",
      "\n",
      "# 9999999\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[3.14278588e-04]\n",
      " [9.99669877e-01]\n",
      " [9.99679949e-01]\n",
      " [3.40533795e-04]]\n",
      "Loss: \n",
      "1.0653708120729777e-07\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Final Results...\n",
      "####################\n",
      "\n",
      "Predicted data based on trained weights: \n",
      "\n",
      "<Train data>\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[3.14278588e-04]\n",
      " [9.99669877e-01]\n",
      " [9.99679949e-01]\n",
      " [3.40533795e-04]]\n",
      "\n",
      "<Test data>\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[3.14278588e-04]\n",
      " [9.99669877e-01]\n",
      " [9.99679949e-01]\n",
      " [3.40533795e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(([0, 0], [0, 1], [1, 0], [1, 1]), dtype=float)\n",
    "y_train = np.array(([0], [1], [1], [0]), dtype=float)\n",
    "\n",
    "X_test = np.array(([0, 0], [0, 1], [1, 0], [1, 1]), dtype=float)\n",
    "y_test = np.array(([0], [1], [1], [0]), dtype=float)\n",
    "\n",
    "# scale units\n",
    "#X_train = X_train / np.amax(X_train, axis=0) # maximum of X array\n",
    "#X_test = X_test / np.amax(X_test, axis=0) # maximum of X_test (our input data for the prediction)\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        #parameters\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 10\n",
    "\n",
    "        #weights\n",
    "        self.w1 = np.random.randn(self.inputSize, self.hiddenSize) # (inputSize x hiddenSize) weight matrix from input to hidden layer\n",
    "        self.w2 = np.random.randn(self.hiddenSize, self.outputSize) # (hiddenSize x outputSize) weight matrix from hidden to output layer\n",
    "    \n",
    "    def forward(self, X):\n",
    "        #forward propagation through our network\n",
    "        self.h1_weighted_sum = np.dot(X, self.w1) # dot product of X (input) and first set of (inputSize x hiddenSize) weights\n",
    "        self.h1_output = self.sigmoid(self.h1_weighted_sum) # activation function\n",
    "        \n",
    "        #fill the following (1), (2)\n",
    "        self.out_weighted_sum=np.dot(self.h1_output,self.w2)# dot product of hidden layer (h1_output) and second set of (hiddenSize x outputSize) weights\n",
    "        output=self.sigmoid(self.out_weighted_sum)# final activation function\n",
    "\n",
    "        return output\n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        # activation function\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        #derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def backward(self, X, y, o, alpha):\n",
    "        # backward propagate through the network\n",
    "        self.o_error = (y - o) # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "        #fill the following (3), (4), (5), (6)\n",
    "        self.h1_error =np.dot(self.o_delta,self.w2.T) # h1 error: how much our hidden layer weights contributed to output error\n",
    "        self.h1_delta = self.h1_error*self.sigmoidPrime(self.h1_output) # applying derivative of sigmoid to h1_output error\n",
    "\n",
    "        self.w1 += np.dot(X.T,self.h1_delta)# adjusting first set (input --> hidden) weights\n",
    "        self.w2 += np.dot(self.h1_output.T,self.o_delta)# adjusting second set (hidden --> output) weights\n",
    "\n",
    "    def train(self, X, y, alpha):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o, alpha)\n",
    "\n",
    "    def saveWeights(self):\n",
    "        np.savetxt(\"w1.txt\", self.w1, fmt=\"%s\")\n",
    "        np.savetxt(\"w2.txt\", self.w2, fmt=\"%s\")\n",
    "\n",
    "    def predict(self):\n",
    "        print(\"\\n\\n####################\")\n",
    "        print(\"Final Results...\")\n",
    "        print(\"####################\\n\")\n",
    "        print(\"Predicted data based on trained weights: \")\n",
    "        print(\"\\n<Train data>\")\n",
    "        print(\"Input: \\n\" + str(X_train))\n",
    "        print(\"Actual Output: \\n\" + str(y_train))\n",
    "        print(\"Predicted Output: \\n\" + str(self.forward(X_train)))\n",
    "        print(\"\\n<Test data>\")\n",
    "        print(\"Input: \\n\" + str(X_train))\n",
    "        print(\"Actual Output: \\n\" + str(y_train))\n",
    "        print(\"Predicted Output: \\n\" + str(self.forward(X_test)))\n",
    "\n",
    "# set a parameter\n",
    "epoch = int(1e7)\n",
    "display_step = int(1e6)\n",
    "alpha = 0.0001        \n",
    "        \n",
    "NN = Neural_Network()\n",
    "\n",
    "for i in range(epoch): # trains the NN 1,000 times\n",
    "    if i % display_step == 0:\n",
    "        print(\"\\n# \" + str(i) + \"\\n\")\n",
    "        print(\"Input: \\n\" + str(X_train))\n",
    "        print(\"Actual Output: \\n\" + str(y_train))\n",
    "        print(\"Predicted Output: \\n\" + str(NN.forward(X_train)))\n",
    "        print(\"Loss: \\n\" + str(np.mean(np.square(y_train - NN.forward(X_train)))))# mean sum squared loss\n",
    "        print()\n",
    "    NN.train(X_train, y_train, alpha)\n",
    "\n",
    "print(\"\\n\\n####################\")\n",
    "print(\"Train is Done...\")\n",
    "print(\"####################\\n\")\n",
    "\n",
    "print(\"\\n# \" + str(i) + \"\\n\")\n",
    "print(\"Input: \\n\" + str(X_train))\n",
    "print(\"Actual Output: \\n\" + str(y_train))\n",
    "print(\"Predicted Output: \\n\" + str(NN.forward(X_train)))\n",
    "print(\"Loss: \\n\" + str(np.mean(np.square(y_train - NN.forward(X_train)))))# mean sum squared loss\n",
    "print()\n",
    "\n",
    "NN.saveWeights()\n",
    "NN.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
