{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. SOLVIGN A XOR PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR PROBLEM\n",
    "![XOR](./XOR_problem.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN example for XOR Problem\n",
    "![NN_Example](./NN_example.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.07628558]\n",
      " [0.08052322]\n",
      " [0.38080836]\n",
      " [0.37445984]]\n",
      "Loss: \n",
      "0.34371887484394104\n",
      "\n",
      "\n",
      "# 1000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.25364436]\n",
      " [0.6994842 ]\n",
      " [0.66202691]\n",
      " [0.37520588]]\n",
      "Loss: \n",
      "0.10241261659468442\n",
      "\n",
      "\n",
      "# 2000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.1467275 ]\n",
      " [0.84013452]\n",
      " [0.82547575]\n",
      " [0.18605464]]\n",
      "Loss: \n",
      "0.028040243250719937\n",
      "\n",
      "\n",
      "# 3000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.10418785]\n",
      " [0.88982014]\n",
      " [0.87974432]\n",
      " [0.12652805]]\n",
      "Loss: \n",
      "0.013366371124431078\n",
      "\n",
      "\n",
      "# 4000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.08316579]\n",
      " [0.91330042]\n",
      " [0.90515657]\n",
      " [0.09914835]]\n",
      "Loss: \n",
      "0.008314759447312126\n",
      "\n",
      "\n",
      "# 5000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0705462 ]\n",
      " [0.92709683]\n",
      " [0.92005892]\n",
      " [0.08323442]]\n",
      "Loss: \n",
      "0.005902545629298801\n",
      "\n",
      "\n",
      "# 6000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.06203132]\n",
      " [0.93628607]\n",
      " [0.92998395]\n",
      " [0.07269386]]\n",
      "Loss: \n",
      "0.004523498559913878\n",
      "\n",
      "\n",
      "# 7000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0558384 ]\n",
      " [0.9429103 ]\n",
      " [0.93714257]\n",
      " [0.06512048]]\n",
      "Loss: \n",
      "0.0036422235567627834\n",
      "\n",
      "\n",
      "# 8000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.05109542]\n",
      " [0.94795016]\n",
      " [0.94259333]\n",
      " [0.05937059]]\n",
      "Loss: \n",
      "0.00303507995709992\n",
      "\n",
      "\n",
      "# 9000000\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.04732385]\n",
      " [0.95193707]\n",
      " [0.94690907]\n",
      " [0.05482843]]\n",
      "Loss: \n",
      "0.0025935990036408604\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Train is Done...\n",
      "####################\n",
      "\n",
      "\n",
      "# 9999999\n",
      "\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.04423811]\n",
      " [0.95518522]\n",
      " [0.95042826]\n",
      " [0.05113156]]\n",
      "Loss: \n",
      "0.002259292381220289\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Final Results...\n",
      "####################\n",
      "\n",
      "Predicted data based on trained weights: \n",
      "\n",
      "<Train data>\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.04423811]\n",
      " [0.95518522]\n",
      " [0.95042826]\n",
      " [0.05113156]]\n",
      "\n",
      "<Test data>\n",
      "Input: \n",
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.04423811]\n",
      " [0.95518522]\n",
      " [0.95042826]\n",
      " [0.05113156]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(([0, 0], [0, 1], [1, 0], [1, 1]), dtype=float)\n",
    "y_train = np.array(([0], [1], [1], [0]), dtype=float)\n",
    "\n",
    "X_test = np.array(([0, 0], [0, 1], [1, 0], [1, 1]), dtype=float)\n",
    "y_test = np.array(([0], [1], [1], [0]), dtype=float)\n",
    "\n",
    "# scale units\n",
    "#X_train = X_train / np.amax(X_train, axis=0) # maximum of X array\n",
    "#X_test = X_test / np.amax(X_test, axis=0) # maximum of X_test (our input data for the prediction)\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        #parameters\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 10\n",
    "\n",
    "        #weights\n",
    "        self.w1 = np.random.randn(self.inputSize, self.hiddenSize) # (inputSize x hiddenSize) weight matrix from input to hidden layer\n",
    "        self.w2 = np.random.randn(self.hiddenSize, self.outputSize) # (hiddenSize x outputSize) weight matrix from hidden to output layer\n",
    "    \n",
    "    def forward(self, X):\n",
    "        #forward propagation through our network\n",
    "        self.h1_weighted_sum = np.dot(X, self.w1) # dot product of X (input) and first set of (inputSize x hiddenSize) weights\n",
    "        self.h1_output = self.sigmoid(self.h1_weighted_sum) # activation function\n",
    "        \n",
    "        #fill the following (1), (2)\n",
    "        (1) # dot product of hidden layer (h1_output) and second set of (hiddenSize x outputSize) weights\n",
    "        (2) # final activation function\n",
    "\n",
    "        return output\n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        # activation function\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        #derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def backward(self, X, y, o, alpha):\n",
    "        # backward propagate through the network\n",
    "        self.o_error = (y - o) # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "        #fill the following (3), (4), (5), (6)\n",
    "        (3) # h1 error: how much our hidden layer weights contributed to output error\n",
    "        (4) # applying derivative of sigmoid to h1_output error\n",
    "        \n",
    "        self.w1 += (5) # adjusting first set (input --> hidden) weights\n",
    "        self.w2 += (6) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "    def train(self, X, y, alpha):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o, alpha)\n",
    "\n",
    "    def saveWeights(self):\n",
    "        np.savetxt(\"w1.txt\", self.w1, fmt=\"%s\")\n",
    "        np.savetxt(\"w2.txt\", self.w2, fmt=\"%s\")\n",
    "\n",
    "    def predict(self):\n",
    "        print(\"\\n\\n####################\")\n",
    "        print(\"Final Results...\")\n",
    "        print(\"####################\\n\")\n",
    "        print(\"Predicted data based on trained weights: \")\n",
    "        print(\"\\n<Train data>\")\n",
    "        print(\"Input: \\n\" + str(X_train))\n",
    "        print(\"Actual Output: \\n\" + str(y_train))\n",
    "        print(\"Predicted Output: \\n\" + str(self.forward(X_train)))\n",
    "        print(\"\\n<Test data>\")\n",
    "        print(\"Input: \\n\" + str(X_train))\n",
    "        print(\"Actual Output: \\n\" + str(y_train))\n",
    "        print(\"Predicted Output: \\n\" + str(self.forward(X_test)))\n",
    "\n",
    "# set a parameter\n",
    "epoch = int(1e7)\n",
    "display_step = int(1e6)\n",
    "alpha = 0.0001        \n",
    "        \n",
    "NN = Neural_Network()\n",
    "\n",
    "for i in range(epoch): # trains the NN 1,000 times\n",
    "    if i % display_step == 0:\n",
    "        print(\"\\n# \" + str(i) + \"\\n\")\n",
    "        print(\"Input: \\n\" + str(X_train))\n",
    "        print(\"Actual Output: \\n\" + str(y_train))\n",
    "        print(\"Predicted Output: \\n\" + str(NN.forward(X_train)))\n",
    "        print(\"Loss: \\n\" + str(np.mean(np.square(y_train - NN.forward(X_train)))))# mean sum squared loss\n",
    "        print()\n",
    "    NN.train(X_train, y_train, alpha)\n",
    "\n",
    "print(\"\\n\\n####################\")\n",
    "print(\"Train is Done...\")\n",
    "print(\"####################\\n\")\n",
    "\n",
    "print(\"\\n# \" + str(i) + \"\\n\")\n",
    "print(\"Input: \\n\" + str(X_train))\n",
    "print(\"Actual Output: \\n\" + str(y_train))\n",
    "print(\"Predicted Output: \\n\" + str(NN.forward(X_train)))\n",
    "print(\"Loss: \\n\" + str(np.mean(np.square(y_train - NN.forward(X_train)))))# mean sum squared loss\n",
    "print()\n",
    "\n",
    "NN.saveWeights()\n",
    "NN.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
